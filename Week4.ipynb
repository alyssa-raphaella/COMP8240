{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Week4.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNJbnA3j+sJj9PejtsU3+CQ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/alyssa-raphaella/COMP8240/blob/master/Week4.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e5mpjAiNE_w4",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "### Reading a CSV File: Process a UCI Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kWOScDyJsy9o",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 263
        },
        "outputId": "a39171f2-7912-424f-a47c-1efaf5576e5e"
      },
      "source": [
        "!wget https://archive.ics.uci.edu/ml/machine-learning-databases/00368/Facebook_metrics.zip\n",
        "!unzip Facebook_metrics.zip"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-08-19 03:12:28--  https://archive.ics.uci.edu/ml/machine-learning-databases/00368/Facebook_metrics.zip\n",
            "Resolving archive.ics.uci.edu (archive.ics.uci.edu)... 128.195.10.252\n",
            "Connecting to archive.ics.uci.edu (archive.ics.uci.edu)|128.195.10.252|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 16281 (16K) [application/x-httpd-php]\n",
            "Saving to: ‘Facebook_metrics.zip’\n",
            "\n",
            "\rFacebook_metrics.zi   0%[                    ]       0  --.-KB/s               \rFacebook_metrics.zi 100%[===================>]  15.90K  --.-KB/s    in 0.06s   \n",
            "\n",
            "2020-08-19 03:12:28 (258 KB/s) - ‘Facebook_metrics.zip’ saved [16281/16281]\n",
            "\n",
            "Archive:  Facebook_metrics.zip\n",
            "  inflating: dataset_Facebook.csv    \n",
            "  inflating: Facebook_metrics.txt    \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gJ5qp6YxB7PG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "outputId": "040dee56-55ee-4f6b-b8ed-6473be859fa4"
      },
      "source": [
        "import csv\n",
        "from collections import defaultdict\n",
        "\n",
        "with open('dataset_Facebook.csv', 'r') as fb_data:\n",
        "  count = defaultdict(int) # count per type\n",
        "  total = defaultdict(int) # total lifetime per type\n",
        "  csv_reader = csv.reader(fb_data, delimiter = ';')\n",
        "  next(csv_reader)\n",
        "  for lines in csv_reader:\n",
        "    total[lines[1]] += int(lines[7])\n",
        "    count[lines[1]] += 1\n",
        "  print(count)\n",
        "  print(total)\n",
        "  for field in total:\n",
        "    print(f'Average of {field}: {total[field]/count[field]}') "
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "defaultdict(<class 'int'>, {'Photo': 426, 'Status': 45, 'Link': 22, 'Video': 7})\n",
            "defaultdict(<class 'int'>, {'Photo': 5596709, 'Status': 588550, 'Link': 407981, 'Video': 358440})\n",
            "Average of Photo: 13137.81455399061\n",
            "Average of Status: 13078.888888888889\n",
            "Average of Link: 18544.590909090908\n",
            "Average of Video: 51205.71428571428\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pgY0T9WLa368",
        "colab_type": "text"
      },
      "source": [
        "### Getting Wikipedia Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CwjLb5-Eu36z",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "outputId": "4c14eee5-1741-41d1-997a-1748cbcb5de8"
      },
      "source": [
        "import wikipedia\n",
        "\n",
        "city = ['Sydney', 'Melbourne', 'Brisbane', 'Canberra', 'Perth']\n",
        "count_prev = 0\n",
        "\n",
        "for x in city:\n",
        "  page = wikipedia.page(x)\n",
        "  info = page.content\n",
        "  count = len(info)\n",
        "  if count_prev < count:\n",
        "    max = x\n",
        "    count_prev = count\n",
        "  print(x, count)\n",
        "print('Max:', max, count_prev)"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Sydney 94986\n",
            "Melbourne 62219\n",
            "Brisbane 64939\n",
            "Canberra 59925\n",
            "Perth 50009\n",
            "Max: Sydney 94986\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oxEG3PR4ap3Y",
        "colab_type": "text"
      },
      "source": [
        "### Writing a CSV File: Counting Word Frequencies"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YUkg3wSGTXFB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 193
        },
        "outputId": "ff03d433-7449-472f-c945-16b126f14257"
      },
      "source": [
        "import re\n",
        "import csv\n",
        "from collections import defaultdict\n",
        "\n",
        "parser = argparse.ArgumentParser()\n",
        "parser.add_argument('input', help = 'input text file filename', type = str)\n",
        "parser.add_argument('output', help = 'output csv filename', type = str)\n",
        "args = parser.parse_args()\n",
        "\n",
        "with open(args.input, 'r') as file:\n",
        "    content = file.read().replace('\\n', '')\n",
        "\n",
        "count = defaultdict(int)\n",
        "\n",
        "content = re.sub(r'[^\\w\\s]', ' ', content)\n",
        "content = content.lower()\n",
        "words = content.split()\n",
        "\n",
        "for x in words:\n",
        "  count[x] += 1\n",
        "\n",
        "for cnt in count:\n",
        "  print(cnt, count[cnt])\n",
        "\n",
        "with open(args.output, 'w') as csvfile:\n",
        "  fieldnames = ['words', 'count']\n",
        "  writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
        "  for cnt in count:\n",
        "    writer.writerow({'words': cnt, 'count': count[cnt]})"
      ],
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "i 1\n",
            "am 2\n",
            "legend 1\n",
            "and 1\n",
            "you 1\n",
            "are 1\n",
            "a 1\n",
            "hero 1\n",
            "peace 1\n",
            "out 2\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}